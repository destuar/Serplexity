/**
 * @file streaming-db-writer.ts
 * @description This file implements `StreamingDatabaseWriter`, a class designed for efficient, high-volume writes to the database,
 * particularly for LLM-generated responses and mentions. It uses batching, concurrency control, and a circuit breaker pattern
 * to ensure robust and performant data ingestion. It also includes logic for extracting mentions from LLM responses based on
 * `<brand>` tags. This is a critical component for handling the large amounts of data generated by the LLMs and persisting it reliably.
 *
 * @dependencies
 * - @prisma/client: The Prisma client for database interactions.
 * - perf_hooks: Node.js module for performance measurement.
 * - ../config/models: LLM configuration, specifically for timeouts.
 *
 * @exports
 * - StreamingDatabaseWriter: A class for streaming data to the database.
 */
import { PrismaClient, Prisma as _Prisma } from "@prisma/client";
import { performance } from "perf_hooks";
import { LLM_CONFIG } from "../config/models";

interface StreamedResponse {
  questionId: string;
  answer: string;
  modelId: string;
  engine: string;
  usage: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  questionType: "visibility" | "benchmark" | "personal";
  citations?: StreamedCitation[];
}

interface StreamedMention {
  position: number;
  entityId: string;
  isCompany: boolean;
}

interface StreamedCitation {
  url: string;
  title: string;
  domain: string;
  accessedAt: Date;
  position: number;
}

interface WriteStats {
  responsesWritten: number;
  mentionsWritten: number;
  citationsWritten: number;
  batchesProcessed: number;
  totalWriteTime: number;
  avgBatchTime: number;
}

interface StreamWriterConfig {
  maxBatchSize: number;
  flushIntervalMs: number;
  maxConcurrentWrites: number;
  useParallelMentionWrites: boolean;
}

export class StreamingDatabaseWriter {
  private prisma: PrismaClient;
  private runId: string;
  private companyId: string;
  private allEntities: { id: string; name: string }[];

  // Buffer management
  private responseBuffer: StreamedResponse[] = [];
  private mentionBuffer: Map<string, StreamedMention[]> = new Map();
  private flushTimer: NodeJS.Timeout | null = null;

  // Performance tracking
  private stats: WriteStats = {
    responsesWritten: 0,
    mentionsWritten: 0,
    citationsWritten: 0,
    batchesProcessed: 0,
    totalWriteTime: 0,
    avgBatchTime: 0,
  };

  // Configuration
  private config: StreamWriterConfig;

  // Concurrency control & adaptive batching
  private activeWrites = 0;
  private pendingFlush = false;
  private dynamicBatchSize: number;
  private readonly MENTION_CHUNK = 500;

  // Circuit breaker for database failures
  private consecutiveFailures = 0;
  private readonly MAX_CONSECUTIVE_FAILURES = 5;
  private circuitBreakerOpen = false;
  private lastFailureTime = 0;
  private readonly CIRCUIT_BREAKER_TIMEOUT = 30000; // 30 seconds

  constructor(
    prisma: PrismaClient,
    runId: string,
    companyId: string,
    allEntities: { id: string; name: string }[],
    config: Partial<StreamWriterConfig> = {},
  ) {
    this.prisma = prisma;
    this.runId = runId;
    this.companyId = companyId;
    this.allEntities = allEntities;

    // Default high-performance configuration
    this.config = {
      maxBatchSize: 75, // Increased batch size for better throughput (observed stable up to 100)
      flushIntervalMs: 3000, // Keep existing flush interval
      maxConcurrentWrites: 2, // Slightly higher concurrency, still avoids deadlocks in testing
      useParallelMentionWrites: false, // Disable parallel mentions to reduce complexity (was true)
      ...config,
    };

    // initialise adaptive batch size with the configured max
    this.dynamicBatchSize = this.config.maxBatchSize;

    this.startFlushTimer();
  }

  /**
   * Stream a response for immediate processing
   * This is called as soon as each LLM response comes in
   */
  async streamResponse(response: StreamedResponse): Promise<void> {
    this.responseBuffer.push(response);

    // Process mentions immediately while response is hot in memory
    const mentions = this.findMentions(response.answer, this.allEntities);
    if (mentions.length > 0) {
      // Use a composite key to avoid overwriting mentions from different models for the same question
      const compositeKey = `${response.questionId}-${response.modelId}`;
      this.mentionBuffer.set(compositeKey, mentions);
    }

    // Trigger immediate flush if buffer is full
    if (this.responseBuffer.length >= this.config.maxBatchSize) {
      await this.flush();
    }
  }

  /**
   * Force flush all pending data - called at the end of processing
   */
  async finalize(): Promise<WriteStats> {
    this.stopFlushTimer();

    // Final flush of any remaining data with timeout protection
    const maxRetries = 10;
    let retryCount = 0;

    while (this.responseBuffer.length > 0 && retryCount < maxRetries) {
      const bufferLengthBefore = this.responseBuffer.length;

      try {
        // Attempt to flush a batch
        await this.flush();

        // If flush is blocked by concurrency, wait a moment before trying again
        if (
          this.activeWrites >= this.config.maxConcurrentWrites &&
          this.responseBuffer.length > 0
        ) {
          await new Promise((resolve) => setTimeout(resolve, 100));
        }

        // Check if we're making progress
        if (this.responseBuffer.length === bufferLengthBefore) {
          retryCount++;
          console.warn(
            `[StreamingDatabaseWriter] No progress in finalize, retry ${retryCount}/${maxRetries}`,
          );

          // Wait longer if no progress is being made
          await new Promise((resolve) => setTimeout(resolve, 500 * retryCount));
        } else {
          retryCount = 0; // Reset retry count if we made progress
        }
      } catch (error) {
        console.error(
          `[StreamingDatabaseWriter] Error during finalize flush:`,
          error,
        );
        retryCount++;

        if (retryCount >= maxRetries) {
          console.error(
            `[StreamingDatabaseWriter] Max retries reached, abandoning ${this.responseBuffer.length} responses`,
          );
          break;
        }

        await new Promise((resolve) => setTimeout(resolve, 1000 * retryCount));
      }
    }

    // Wait for the last batch(es) to finish writing with timeout
    const maxWaitTime = 60000; // 60 seconds max wait
    const startWait = Date.now();

    while (this.activeWrites > 0) {
      if (Date.now() - startWait > maxWaitTime) {
        console.error(
          `[StreamingDatabaseWriter] Timeout waiting for active writes to complete. ${this.activeWrites} writes still active.`,
        );
        break;
      }
      await new Promise((resolve) => setTimeout(resolve, 100));
    }

    if (this.responseBuffer.length > 0) {
      console.warn(
        `[StreamingDatabaseWriter] Finalize completed with ${this.responseBuffer.length} responses remaining in buffer`,
      );
    }

    return this.stats;
  }

  private startFlushTimer(): void {
    this.flushTimer = setInterval(() => {
      if (this.responseBuffer.length > 0 && !this.pendingFlush) {
        this.flush().catch((error) => {
          console.error("[StreamingDatabaseWriter] Timer flush failed:", error);
        });
      }
    }, this.config.flushIntervalMs);
  }

  private stopFlushTimer(): void {
    if (this.flushTimer) {
      clearInterval(this.flushTimer);
      this.flushTimer = null;
    }
  }

  private async flush(): Promise<void> {
    if (this.pendingFlush || this.responseBuffer.length === 0) {
      return;
    }

    if (this.activeWrites >= this.config.maxConcurrentWrites) {
      return; // Wait for some writes to complete
    }

    // Check circuit breaker
    if (this.circuitBreakerOpen) {
      if (Date.now() - this.lastFailureTime > this.CIRCUIT_BREAKER_TIMEOUT) {
        console.log(
          "[StreamingDatabaseWriter] Circuit breaker timeout expired, attempting to reset",
        );
        this.circuitBreakerOpen = false;
        this.consecutiveFailures = 0;
      } else {
        console.warn(
          "[StreamingDatabaseWriter] Circuit breaker is open, skipping flush",
        );
        return;
      }
    }

    this.pendingFlush = true;
    this.activeWrites++;

    // pick size based on adaptive algorithm
    const batchSize = Math.min(
      this.dynamicBatchSize,
      this.responseBuffer.length,
    );
    const batchToProcess = this.responseBuffer.splice(0, batchSize);
    const batchStartTime = performance.now();

    try {
      await this.processBatch(batchToProcess);

      const batchTime = performance.now() - batchStartTime;
      this.stats.batchesProcessed++;
      this.stats.totalWriteTime += batchTime;
      this.stats.avgBatchTime =
        this.stats.totalWriteTime / this.stats.batchesProcessed;

      // Reset circuit breaker on success
      this.consecutiveFailures = 0;
      this.circuitBreakerOpen = false;

      // --- adaptive batch tuning ---
      const TARGET_MS = 3000; // Increased target to 3s per batch (was 1.5s)
      if (batchTime > TARGET_MS * 1.5 && this.dynamicBatchSize > 5) {
        this.dynamicBatchSize = Math.max(5, this.dynamicBatchSize - 5); // Smaller adjustments
      } else if (batchTime < TARGET_MS * 0.5 && this.dynamicBatchSize < 50) {
        this.dynamicBatchSize += 5; // Smaller adjustments
      }

      console.log(
        `[StreamingDatabaseWriter] Batch ${this.stats.batchesProcessed} completed in ${batchTime.toFixed(2)}ms (${batchToProcess.length} responses) - Dynamic batch size: ${this.dynamicBatchSize}`,
      );
    } catch (error) {
      console.error(
        "[StreamingDatabaseWriter] Batch processing failed:",
        error,
      );

      // Increment failure counter
      this.consecutiveFailures++;
      this.lastFailureTime = Date.now();

      // Open circuit breaker if too many consecutive failures
      if (this.consecutiveFailures >= this.MAX_CONSECUTIVE_FAILURES) {
        this.circuitBreakerOpen = true;
        console.error(
          `[StreamingDatabaseWriter] Circuit breaker opened after ${this.consecutiveFailures} consecutive failures`,
        );
      }

      // Add detailed error logging
      if (error instanceof Error) {
        console.error(
          `[StreamingDatabaseWriter] Error details: ${error.name}: ${error.message}`,
        );
        if (error.stack) {
          console.error(
            `[StreamingDatabaseWriter] Stack trace: ${error.stack.split("\n").slice(0, 5).join("\n")}`,
          );
        }
      }

      // Put failed responses back in buffer for retry (only if circuit breaker is not open)
      if (!this.circuitBreakerOpen) {
        this.responseBuffer.unshift(...batchToProcess);
      } else {
        console.warn(
          `[StreamingDatabaseWriter] Circuit breaker open, dropping ${batchToProcess.length} responses`,
        );
      }

      // Adaptive batch size reduction on errors
      if (this.dynamicBatchSize > 5) {
        this.dynamicBatchSize = Math.max(
          5,
          Math.floor(this.dynamicBatchSize * 0.7),
        );
        console.warn(
          `[StreamingDatabaseWriter] Error encountered, reducing batch size to ${this.dynamicBatchSize}`,
        );
      }
    } finally {
      this.activeWrites--;
      this.pendingFlush = false;
    }
  }

  private async processBatch(responses: StreamedResponse[]): Promise<void> {
    // Group responses by type for optimal batching
    const _visibilityResponses = responses.filter(
      (r) => r.questionType === "visibility",
    );
    const _benchmarkResponses = responses.filter(
      (r) => r.questionType === "benchmark",
    );
    const _personalResponses = responses.filter(
      (r) => r.questionType === "personal",
    );

    // Process each type in parallel using separate transactions
    const writePromises: Promise<void>[] = [];

    // New architecture: all responses are response-based
    if (responses.length > 0) {
      writePromises.push(this.writeResponses(responses));
    }

    await Promise.all(writePromises);
    this.stats.responsesWritten += responses.length;
  }

  // ===== New Fanout write path =====
  private async ensureQuestions(questionIds: string[]): Promise<void> {
    // Remove any duplicates first
    const uniqueIds = Array.from(new Set(questionIds));

    if (uniqueIds.length === 0) return;

    // Fetch all Question ids that already exist
    const existing = await this.prisma.question.findMany({
      where: { id: { in: uniqueIds } },
      select: { id: true },
    });
    const existingIds = new Set(existing.map((q) => q.id));

    // Determine which ids are missing
    const missingIds = uniqueIds.filter((id) => !existingIds.has(id));
    if (missingIds.length === 0) return;

    // Attempt to look them up in the legacy question table so we can preserve query
    const legacyQuestions = await this.prisma.question.findMany({
      where: { id: { in: missingIds } },
      select: { id: true, query: true },
    });
    const legacyMap = new Map(legacyQuestions.map((q: { id: string; query: string }) => [q.id, q.query]));

    const stubData = missingIds.map((id) => ({
      id, // preserve the original id so downstream references remain valid
      query: legacyMap.get(id) ?? "Legacy question",
      companyId: this.companyId,
      source: "user", // Legacy questions treated as user questions
      isActive: false,
    }));

    await this.prisma.question.createMany({
      data: stubData,
      skipDuplicates: true,
    });
  }

  private async writeResponses(responses: StreamedResponse[]): Promise<void> {
    // Ensure all referenced Question records exist (handles legacy benchmark questions)
    await this.ensureQuestions(responses.map((r) => r.questionId));

    await this.prisma.$transaction(
      async (tx) => {
        await tx.$executeRawUnsafe("SET LOCAL statement_timeout = 60000");
        await tx.$executeRawUnsafe("SET LOCAL deadlock_timeout = '5s'");
        await tx.$executeRawUnsafe("SET LOCAL lock_timeout = '10s'");

        for (const r of responses) {
          // Insert each response individually to obtain ID for mentions
          const created = await tx.response.create({
            data: {
              questionId: r.questionId,
              engine: r.engine,
              model: r.modelId,
              content: r.answer,
              runId: this.runId,
            },
          });

          const compositeKey = `${r.questionId}-${r.modelId}`;
          const mentions = this.mentionBuffer.get(compositeKey) || [];
          if (mentions.length > 0) {
            for (let j = 0; j < mentions.length; j += this.MENTION_CHUNK) {
              const chunk = mentions.slice(j, j + this.MENTION_CHUNK);
              await tx.mention.createMany({
                data: chunk.map((m) => ({
                  responseId: created.id,
                  position: m.position,
                  ...(m.isCompany
                    ? { companyId: m.entityId }
                    : { competitorId: m.entityId }),
                })),
              });
            }
            this.stats.mentionsWritten += mentions.length;
          }

          // Handle citations if present
          if (r.citations && r.citations.length > 0) {
            await tx.citation.createMany({
              data: r.citations.map((c) => ({
                responseId: created.id,
                url: c.url,
                title: c.title,
                domain: c.domain,
                accessedAt: c.accessedAt,
                position: c.position,
              })),
            });
            this.stats.citationsWritten += r.citations.length;
          }
        }
      },
      {
        maxWait: LLM_CONFIG.TIMEOUTS.STREAMING_BATCH_MAX_WAIT,
        timeout: LLM_CONFIG.TIMEOUTS.STREAMING_BATCH_TIMEOUT,
        isolationLevel: "ReadCommitted",
      },
    );
  }
  // Legacy-specific write functions have been removed in favour of unified fan-out writing.

  /**
   * Extract mentions based solely on explicit <brand> tags.
   * If no valid <brand> tags are present, no mentions are recorded.
   */
  private findMentions(
    text: string,
    entities: { id: string; name: string }[],
  ): StreamedMention[] {
    const brandTagRegex = /<brand>(.*?)<\/brand>/gi;
    const taggedMentions: { name: string; index: number }[] = [];
    let match;

    while ((match = brandTagRegex.exec(text)) !== null) {
      taggedMentions.push({ name: match[1].trim(), index: match.index });
    }

    // Debug: Log responses without brand tags for analysis
    if (taggedMentions.length === 0) {
      const truncatedText =
        text.length > 200 ? text.substring(0, 200) + "..." : text;
      console.log(
        `[StreamingDatabaseWriter] No <brand> tags found in response: "${truncatedText}"`,
      );
    }

    // --- Strategy 1: Use <brand> tags if they exist ---
    if (taggedMentions.length > 0) {
      console.log(
        `[StreamingDatabaseWriter] Found ${taggedMentions.length} brand tags:`,
        taggedMentions.map((t) => t.name),
      );

      const uniqueMentions = new Map<string, StreamedMention>();
      let position = 1;

      // Sort tagged mentions by their appearance order
      taggedMentions.sort((a, b) => a.index - b.index);

      // Create a map of normalized entity names to their IDs
      const entityMap = new Map<string, string>();
      for (const entity of entities) {
        // This simple normalization should be sufficient as we rely on the LLM's spelling.
        entityMap.set(entity.name.toLowerCase().trim(), entity.id);
      }

      for (const tagged of taggedMentions) {
        const taggedNameLower = tagged.name.toLowerCase().trim();
        const entityId = entityMap.get(taggedNameLower);

        if (entityId) {
          console.log(
            `[StreamingDatabaseWriter] Matched brand "${tagged.name}" to entity ${entityId}`,
          );
        } else {
          console.log(
            `[StreamingDatabaseWriter] Brand "${tagged.name}" not found in known entities:`,
            entities.map((e) => e.name),
          );
        }

        if (entityId && !uniqueMentions.has(entityId)) {
          uniqueMentions.set(entityId, {
            position: position++,
            entityId: entityId,
            isCompany: entityId === this.companyId,
          });
        }
      }

      // If we found valid, known entities in the tags, return them.
      if (uniqueMentions.size > 0) {
        console.log(
          `[StreamingDatabaseWriter] Returning ${uniqueMentions.size} valid mentions`,
        );
        return Array.from(uniqueMentions.values());
      }
    }

    // No <brand> tags found or no matching entities identified; skip mention detection.
    return [];
  }

  private escapeRegex(string: string): string {
    return string.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
  }
}
